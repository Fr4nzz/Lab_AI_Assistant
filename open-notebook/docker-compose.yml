# Open Notebook with Claude Code (Max Subscription)
#
# This setup uses Claude Code via your Max subscription instead of API keys.
# The Claude Code proxy runs locally (not in Docker) to use your authenticated Claude.
#
# SETUP:
# 1. First, start the Claude Code proxy locally:
#    cd claude-code-proxy
#    run.bat  (Windows) or ./run.sh (Linux/macOS)
#
# 2. Then start Open Notebook:
#    docker compose up -d
#
# 3. Access Open Notebook at: http://localhost:8502

services:
  # SurrealDB - Database for Open Notebook
  surrealdb:
    image: surrealdb/surrealdb:v2
    container_name: open-notebook-db
    # Use memory storage to avoid permission issues, or use file with proper path
    command: start --user root --pass password --bind 0.0.0.0:8000 memory
    # For persistent storage, uncomment below and comment out memory line above:
    # command: start --user root --pass password --bind 0.0.0.0:8000 file:/data/database.db
    ports:
      - "8000:8000"
    volumes:
      - surreal_data:/data
    user: root
    restart: unless-stopped

  # Open Notebook - Main Application
  open_notebook:
    image: lfnovo/open_notebook:v1-latest
    container_name: open-notebook-app
    ports:
      - "8502:8502"  # Web UI
      - "5055:5055"  # REST API
    environment:
      # Database connection
      - SURREAL_URL=ws://surrealdb:8000/rpc
      - SURREAL_USER=root
      - SURREAL_PASSWORD=password
      - SURREAL_NAMESPACE=open_notebook
      - SURREAL_DATABASE=open_notebook

      # Claude Code Proxy (OpenAI-compatible endpoint)
      # host.docker.internal allows Docker to connect to host machine
      - OPENAI_COMPATIBLE_BASE_URL_LLM=http://host.docker.internal:8080/v1
      - OPENAI_COMPATIBLE_API_KEY_LLM=dummy-key

      # For embeddings, you'll need a separate provider since Claude Code
      # doesn't provide embeddings. Options:
      # Option 1: Use OpenAI for embeddings only (requires API key)
      # - OPENAI_API_KEY=sk-...
      #
      # Option 2: Use Ollama for local embeddings (see ollama service below)
      # - OLLAMA_API_BASE=http://ollama:11434
      #
      # Option 3: Use free Voyage AI embeddings
      # - VOYAGE_API_KEY=...

      # Timeout settings (Claude Code can be slow)
      - ESPERANTO_LLM_TIMEOUT=120
      - API_CLIENT_TIMEOUT=300

      # Optional: Password protect your instance
      # - OPEN_NOTEBOOK_PASSWORD=your-password

    volumes:
      - ./notebook_data:/app/data
    depends_on:
      - surrealdb
    extra_hosts:
      - "host.docker.internal:host-gateway"  # Allow access to host machine
    restart: unless-stopped

  # Optional: Ollama for local embeddings (uncomment if needed)
  # This provides free local embeddings without API keys
  # ollama:
  #   image: ollama/ollama:latest
  #   container_name: open-notebook-ollama
  #   ports:
  #     - "11434:11434"
  #   volumes:
  #     - ollama_models:/root/.ollama
  #   environment:
  #     - OLLAMA_HOST=0.0.0.0:11434
  #   restart: unless-stopped
  #   # After starting, run: docker exec open-notebook-ollama ollama pull nomic-embed-text

volumes:
  surreal_data:
  # ollama_models:  # Uncomment if using Ollama
